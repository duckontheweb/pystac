name: Benchmarks

on:
  pull_request:
    types: [opened, reopened, synchronize, labeled]
  workflow_dispatch:

jobs:
  benchmark:
    if: ${{ contains( github.event.pull_request.labels.*.name, 'run-benchmarks') && github.event_name == 'pull_request' || github.event_name == 'workflow_dispatch' }}
    name: Linux
    runs-on: ubuntu-20.04

    strategy:
      # Allow other matrix jobs to complete if 1 fails
      fail-fast: false
      matrix:
        python-version:
          - "3.8"
          - "3.9"
          - "3.10"

    env:
      ASV_DIR: "./benchmarks"
    steps:
      # We need the full repo to avoid this issue
      # https://github.com/actions/checkout/issues/23
      - uses: actions/checkout@v2
        with:
          fetch-depth: 0

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v2
        with:
          python-version: ${{ matrix.python-version }}

      - name: Cache dependencies
        uses: actions/cache@v2
        with:
          path: ~/.cache/pip
          # Cache based on OS, Python version, and dependency hash
          key: pip-benchmarks-python${{ matrix.python-version }}-${{ hashFiles('requirements-bench.txt') }}
        
      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install -r requirements-bench.txt
          pip install -e .

      - name: Run benchmarks
        id: benchmark
        run: |
          set -x
          # ID this runner
          asv machine --yes
          echo "Baseline:  ${{ github.event.pull_request.base.sha }} (${{ github.event.pull_request.base.label }})"
          echo "Contender: ${GITHUB_SHA} (${{ github.event.pull_request.head.label }})"
          # Run benchmarks for current commit against base
          ASV_OPTIONS="--split -e --interleave-rounds"
          asv continuous $ASV_OPTIONS ${{ github.event.pull_request.base.sha }} ${GITHUB_SHA} \
              | tee benchmarks.log
          # Report and export results for subsequent steps
          if grep "Traceback \|failed\|PERFORMANCE DECREASED" benchmarks.log > /dev/null ; then
              exit 1
          fi
        working-directory: ${{ env.ASV_DIR }}

      - name: Add instructions to artifact
        if: always()
        run: |
          cp benchmarks.log .asv/results/
        working-directory: ${{ env.ASV_DIR }}

      - uses: actions/upload-artifact@v2
        if: always()
        with:
          name: asv-benchmark-results-${{ runner.os }}
          path: ${{ env.ASV_DIR }}/.asv/results